"""
ARIAKE_CVI (DeepGPET based) - Streamlit Cloud Ready Version
Developer: Team Yanagi
ç‰¹å®šã®URLã‚’çŸ¥ã£ã¦ã„ã‚‹ãƒ¡ãƒ³ãƒãƒ¼ã®ã¿ãŒåˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã€ç°¡æ˜“èªè¨¼ã¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã‚’å®Ÿè£…ã€‚
åˆå›ã®è§£ææ™‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•åˆæœŸåŒ–ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£å‘ä¸Šç‰ˆã€‚
"""
import sys
import os
from pathlib import Path
import streamlit as st
import numpy as np
import cv2
from PIL import Image
import pandas as pd
from datetime import datetime
import io
import zipfile
from streamlit_image_coordinates import streamlit_image_coordinates

# DeepGPET module path setup
deepgpet_path = Path(__file__).resolve().parent / 'deepgpet'
sys.path.insert(0, str(deepgpet_path))

try:
    from choseg import inference
except ImportError as e:
    error_msg = str(e)
    if 'torch' in error_msg:
        st.error(f"""
        âš ï¸ **PyTorchãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“**
        
        ç¾åœ¨ã®Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆ{sys.version.split()[0]}ï¼‰ã§ã¯PyTorchãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ããªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
        
        **è§£æ±ºæ–¹æ³•:**
        1. Python 3.11ã¾ãŸã¯3.12ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
        2. ä»®æƒ³ç’°å¢ƒã‚’å†ä½œæˆã—ã¦ãã ã•ã„:
           ```
           python3.11 -m venv venv
           source venv/bin/activate
           pip install -r requirements.txt
           ```
        
        è©³ç´°ã‚¨ãƒ©ãƒ¼: {error_msg}
        """)
    else:
        st.error(f"âš ï¸ DeepGPETãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚deepgpetãƒ•ã‚©ãƒ«ãƒ€ãŒåŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n\nã‚¨ãƒ©ãƒ¼: {error_msg}")
    
    class MockModel:
        def __call__(self, img):
            # Ensure numpy array output consistent with real model
            if isinstance(img, Image.Image):
                img = np.array(img)
            return np.zeros(img.shape, dtype=np.float32)
    inference = type('obj', (object,), {'DeepGPET': MockModel})

APP_NAME = "ARIAKE_CVI"
DEVELOPER = "Team Yanagi"
ACCESS_KEY = "ariake2024"  # å…¬é–‹æ™‚ã«å…±æœ‰ã™ã‚‹ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ï¼ˆå¿…è¦ã«å¿œã˜ã¦å¤‰æ›´ã—ã¦ãã ã•ã„ï¼‰

# ==========================================
# è§£æãƒ­ã‚¸ãƒƒã‚¯ (CVIProcessor)
# ==========================================
class CVIProcessor:
    def __init__(self):
        self.model = None
        
    def initialize_model(self):
        if self.model is None:
            self.model = inference.DeepGPET()
    
    def niblack_threshold(self, img, mask, radius=15, k=0.2):
        img_float = img.astype(np.float32)
        kernel_size = 2 * radius + 1
        mean = cv2.blur(img_float, (kernel_size, kernel_size), borderType=cv2.BORDER_REFLECT)
        mean_sq = cv2.blur(img_float ** 2, (kernel_size, kernel_size), borderType=cv2.BORDER_REFLECT)
        variance = mean_sq - (mean ** 2)
        std_dev = np.sqrt(np.maximum(variance, 0))
        threshold = mean + k * std_dev
        binary = (img_float < threshold).astype(np.uint8) * 255
        binary[mask == 0] = 0
        return binary

    def denoise_image_global(self, img):
        smoothed = cv2.GaussianBlur(img, (3, 3), 0)
        img_float = smoothed.astype(np.float32) / 255.0
        j_raw = np.power(img_float, 4)
        sum_j_raw = np.cumsum(np.power(j_raw, 2)[::-1], axis=0)[::-1]
        sum_j_raw[sum_j_raw == 0] = 1e-6
        j_raw_squared = np.power(j_raw, 2)
        enhanced = 255 * np.power(j_raw_squared / (2 * sum_j_raw), 0.25)
        result = np.clip(enhanced, 0, 255).astype(np.uint8)
        result = cv2.medianBlur(result, 3)
        return result

    def get_roi_metrics(self, global_lum_mask, mask, fovea_x, scale_px_per_mm_h, scale_px_per_mm_v, width_mm):
        height, width = mask.shape
        
        # Validate fovea position
        fovea_x = max(0, min(fovea_x, width - 1))
        
        roi_width_px = int(width_mm * scale_px_per_mm_h)
        roi_start_x = max(0, int(fovea_x - roi_width_px / 2))
        roi_end_x = min(width, roi_start_x + roi_width_px)
        actual_roi_width_px = roi_end_x - roi_start_x
        if actual_roi_width_px <= 0:
            return 0.0, 0.0, 0.0, 0.0, None
        roi_mask = mask[:, roi_start_x:roi_end_x]
        roi_lum = global_lum_mask[:, roi_start_x:roi_end_x]
        tca_px = np.sum(roi_mask > 0)
        la_px = np.sum(roi_lum > 0)
        pixel_area_mm2 = (1.0 / scale_px_per_mm_h) * (1.0 / scale_px_per_mm_v)
        tca_mm2 = tca_px * pixel_area_mm2
        la_mm2 = la_px * pixel_area_mm2
        cvi = (la_mm2 / tca_mm2 * 100) if tca_mm2 > 0 else 0.0
        ct_um = (tca_mm2 / (actual_roi_width_px / scale_px_per_mm_h)) * 1000
        return tca_mm2, ct_um, cvi, la_mm2, roi_lum

    def process_image(self, pil_img, filename, fovea_x, fovea_y, scan_width_mm, depth_range_mm):
        try:
            img_gray = np.array(pil_img.convert('L'))
            height, width = img_gray.shape
            
            # Validate fovea coordinates
            fovea_x = max(0, min(int(fovea_x), width - 1))
            fovea_y = max(0, min(int(fovea_y), height - 1))
            
            scale_px_per_mm_h = width / scan_width_mm
            scale_px_per_mm_v = height / depth_range_mm
            
            # Segmentation
            img_seg = self.model(Image.fromarray(img_gray))
            if isinstance(img_seg, np.ndarray):
                mask = (img_seg > 0.5).astype(np.uint8) * 255
            else:
                mask = np.zeros((height, width), dtype=np.uint8)
            
            # Denoising & Thresholding
            denoised_img = self.denoise_image_global(img_gray)
            global_lum_mask = self.niblack_threshold(img_gray, mask)
            global_dlum_mask = self.niblack_threshold(denoised_img, mask)
            
            global_lum_mask = cv2.medianBlur(global_lum_mask, 3)
            global_dlum_mask = cv2.medianBlur(global_dlum_mask, 3)
            global_lum_mask[mask == 0] = 0
            global_dlum_mask[mask == 0] = 0
            
            # Get Metrics
            tca15, ct15, cvi15, _, _ = self.get_roi_metrics(global_lum_mask, mask, fovea_x, scale_px_per_mm_h, scale_px_per_mm_v, 1.5)
            tca30, ct30, cvi30, _, lum30_roi = self.get_roi_metrics(global_lum_mask, mask, fovea_x, scale_px_per_mm_h, scale_px_per_mm_v, 3.0)
            dtca15, dct15, dcvi15, _, _ = self.get_roi_metrics(global_dlum_mask, mask, fovea_x, scale_px_per_mm_h, scale_px_per_mm_v, 1.5)
            dtca30, dct30, dcvi30, _, dlum30_roi = self.get_roi_metrics(global_dlum_mask, mask, fovea_x, scale_px_per_mm_h, scale_px_per_mm_v, 3.0)
        
            # Generate visualization images for download/preview
            def create_vis_buffer(base_img, l_mask_roi):
                vis = cv2.cvtColor(base_img, cv2.COLOR_GRAY2RGB)
                roi_w_px = int(3.0 * scale_px_per_mm_h)
                rx_start = max(0, int(fovea_x - roi_w_px / 2))
                rx_end = min(width, rx_start + roi_w_px)
                full_v_mask = np.zeros_like(mask)
                if l_mask_roi is not None: full_v_mask[:, rx_start:rx_end] = l_mask_roi
                vis[full_v_mask > 0] = [0, 0, 0] 
                contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(vis, contours, -1, (0, 255, 255), 1) 
                cv2.circle(vis, (int(fovea_x), int(fovea_y)), 8, (0, 255, 0), -1) 
                cv2.line(vis, (rx_start, 0), (rx_start, height), (255, 0, 0), 2)
                cv2.line(vis, (rx_end, 0), (rx_end, height), (255, 0, 0), 2)
                is_success, buffer = cv2.imencode(".jpg", vis)
                return buffer.tobytes() if is_success else None

            vis_cvi = create_vis_buffer(img_gray, lum30_roi)
            vis_dcvi = create_vis_buffer(denoised_img, dlum30_roi)

            stats = {
                'Image ID': filename,
                'TCA 1.5mm (mm2)': round(tca15, 4),
                'CT 1.5mm (um)': round(ct15, 2),
                'CVI 1.5mm (%)': round(cvi15, 2),
                'D-CVI 1.5mm (%)': round(dcvi15, 2),
                'TCA 3.0mm (mm2)': round(tca30, 4),
                'CT 3.0mm (um)': round(ct30, 2),
                'CVI 3.0mm (%)': round(cvi30, 2),
                'D-CVI 3.0mm (%)': round(dcvi30, 2)
            }
            return stats, vis_cvi, vis_dcvi
        except Exception as e:
            st.error(f"âŒ Error processing {filename}: {str(e)}")
            return None, None, None

# ==========================================
# Streamlit UI
# ==========================================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®åˆæœŸçŠ¶æ…‹ã‚’è¨­å®šï¼ˆç”»åƒå‡¦ç†ä¸­ã¯è‡ªå‹•çš„ã«é–‰ã˜ã‚‹ï¼‰
if 'processing_started' not in st.session_state:
    st.session_state.processing_started = False

initial_sidebar_state = "collapsed" if st.session_state.processing_started else "expanded"
st.set_page_config(page_title=APP_NAME, layout="wide", initial_sidebar_state=initial_sidebar_state)

# ã‚«ã‚¹ã‚¿ãƒ CSS: ç”»åƒã®ä½ç½®ã‚’å®Œå…¨ã«çµ±ä¸€
st.markdown("""
<style>
    /* streamlit_image_coordinatesã¨st.imageã®è¡¨ç¤ºä½ç½®ã‚’çµ±ä¸€ */
    div[data-testid="stImage"],
    div[data-testid="stImageContainer"] {
        display: flex !important;
        justify-content: flex-start !important;
        align-items: flex-start !important;
        margin: 0 !important;
        padding: 0 !important;
    }
    
    div[data-testid="stImage"] > img,
    div[data-testid="stImageContainer"] > img {
        margin: 0 !important;
        padding: 0 !important;
    }
</style>
""", unsafe_allow_html=True)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–
if 'authenticated' not in st.session_state:
    st.session_state.authenticated = False
if 'current_idx' not in st.session_state:
    st.session_state.current_idx = 0
if 'results' not in st.session_state:
    st.session_state.results = []
if 'vis_files' not in st.session_state:
    st.session_state.vis_files = {} # filename -> bytes
if 'input_path' not in st.session_state:
    st.session_state.input_path = ""
if 'output_path' not in st.session_state:
    st.session_state.output_path = ""
if 'browsing_for' not in st.session_state:
    st.session_state.browsing_for = None  # "input" or "output"
if 'current_browse_path' not in st.session_state:
    st.session_state.current_browse_path = str(Path.home())
if 'fovea_clicked' not in st.session_state:
    st.session_state.fovea_clicked = {}  # idx -> (fx, fy)

# --- èªè¨¼ç”»é¢ ---
if not st.session_state.authenticated:
    st.title(f"ğŸ” {APP_NAME} Login")
    pwd = st.text_input("Enter Access Key", type="password")
    if st.button("Login"):
        if pwd == ACCESS_KEY:
            st.session_state.authenticated = True
            st.rerun()
        else:
            st.error("Invalid Access Key.")
    st.stop()

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
st.title(f"ğŸš€ {APP_NAME}")
st.markdown(f"*Developed by {DEVELOPER}*")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
with st.sidebar:
    st.header("âš™ï¸ Settings")
    
    # å‡¦ç†ãƒ¢ãƒ¼ãƒ‰é¸æŠ
    mode = st.radio("Processing Mode", ["File Upload", "Folder Batch"])
    
    if mode == "File Upload":
        uploaded_files = st.file_uploader(
            "Upload B-scan Images", 
            type=['png', 'jpg', 'jpeg', 'tif', 'tiff'], 
            accept_multiple_files=True
        )
        # File Uploadãƒ¢ãƒ¼ãƒ‰ã§ã¯å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼æŒ‡å®šãªã—ï¼ˆZipãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã®ã¿ï¼‰
        output_folder = None
    else:
        st.markdown("**ğŸ“ Folder Paths**")
        
        # ========== Input Folder Selection ==========
        col1, col2 = st.columns([3, 1])
        with col1:
            input_folder = st.text_input(
                "Input Folder", 
                value=st.session_state.input_path,
                placeholder="/Users/y/Github/input",
                key="input_folder_text"
            )
        with col2:
            if st.button("ğŸ“‚ Browse", key="browse_input"):
                st.session_state.browsing_for = "input"
                st.session_state.current_browse_path = st.session_state.input_path if st.session_state.input_path else str(Path.home())
        
        # ========== Output Folder Selection ==========
        col1, col2 = st.columns([3, 1])
        with col1:
            output_folder = st.text_input(
                "Output Folder", 
                value=st.session_state.output_path,
                placeholder="/Users/y/Github/output",
                key="output_folder_text"
            )
        with col2:
            if st.button("ğŸ“‚ Browse", key="browse_output"):
                st.session_state.browsing_for = "output"
                st.session_state.current_browse_path = st.session_state.output_path if st.session_state.output_path else str(Path.home())
        
        # ========== Folder Browser Dialog ==========
        if st.session_state.browsing_for:
            st.markdown("---")
            st.markdown(f"### ğŸ“‚ Select {'Input' if st.session_state.browsing_for == 'input' else 'Output'} Folder")
            
            # Quick Access Shortcuts
            quick_paths = {
                "ğŸ  Home": str(Path.home()),
                "ğŸ–¥ï¸ Desktop": str(Path.home() / "Desktop"),
                "ğŸ“„ Documents": str(Path.home() / "Documents"),
                "ğŸ“¥ Downloads": str(Path.home() / "Downloads"),
            }
            
            cols = st.columns(len(quick_paths))
            for idx, (label, path) in enumerate(quick_paths.items()):
                with cols[idx]:
                    if st.button(label, key=f"quick_{idx}", use_container_width=True):
                        st.session_state.current_browse_path = path
                        st.rerun()
            
            # Current Path Display
            browse_path = Path(st.session_state.current_browse_path)
            st.text_input("Current Path:", value=str(browse_path), disabled=True, key="current_path_display")
            
            # Parent Directory Button
            if browse_path.parent != browse_path:
                if st.button("â¬†ï¸ Parent Folder", use_container_width=True):
                    st.session_state.current_browse_path = str(browse_path.parent)
                    st.rerun()
            
            # List subdirectories
            try:
                subdirs = sorted([d for d in browse_path.iterdir() if d.is_dir()], key=lambda x: x.name.lower())
                if subdirs:
                    st.markdown("**Folders:**")
                    for subdir in subdirs[:20]:  # Limit to 20 for performance
                        col1, col2 = st.columns([4, 1])
                        with col1:
                            st.text(f"ğŸ“ {subdir.name}")
                        with col2:
                            if st.button("Open", key=f"open_{subdir.name}"):
                                st.session_state.current_browse_path = str(subdir)
                                st.rerun()
                else:
                    st.info("No subfolders found")
            except PermissionError:
                st.error("âŒ Permission denied")
            except Exception as e:
                st.error(f"âŒ Error: {str(e)}")
            
            # Confirm Selection
            col1, col2 = st.columns(2)
            with col1:
                if st.button("âœ… Select This Folder", type="primary", use_container_width=True):
                    if st.session_state.browsing_for == "input":
                        st.session_state.input_path = st.session_state.current_browse_path
                    else:
                        st.session_state.output_path = st.session_state.current_browse_path
                    st.session_state.browsing_for = None
                    st.rerun()
            with col2:
                if st.button("âŒ Cancel", use_container_width=True):
                    st.session_state.browsing_for = None
                    st.rerun()
            
            st.markdown("---")
        
        uploaded_files = []
        if input_folder and os.path.exists(input_folder):
            try:
                image_files = sorted(
                    list(Path(input_folder).glob("*.png")) + 
                    list(Path(input_folder).glob("*.jpg")) + 
                    list(Path(input_folder).glob("*.jpeg")) +
                    list(Path(input_folder).glob("*.tif")) +
                    list(Path(input_folder).glob("*.tiff"))
                )
                st.info(f"âœ… Found {len(image_files)} images")
                uploaded_files = image_files
            except Exception as e:
                st.error(f"âŒ Error reading folder: {str(e)}")
        elif input_folder:
            st.error(f"âŒ Folder path does not exist: {input_folder}")
        
        # Folder Batchãƒ¢ãƒ¼ãƒ‰ã§ã¯å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ãŒå¿…é ˆ
        if output_folder and not os.path.exists(output_folder):
            st.warning(f"âš ï¸ Output folder will be created: {output_folder}")
    
    scan_w = st.number_input("Scan Width (mm)", value=12.0, min_value=0.1)
    depth_r = st.number_input("Depth Range (mm)", value=2.6, min_value=0.1)
    author = st.text_input("Author", value="YY")
    
    st.divider()
    
    # ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰çŠ¶æ…‹ã‚’è¡¨ç¤º
    if 'processor' in st.session_state:
        st.success("âœ… AI Model Loaded")
    else:
        st.info("â„¹ï¸ Model will be loaded automatically on first analysis")

# è§£æå‡¦ç†
if uploaded_files:
    # ç”»åƒå‡¦ç†ãŒé–‹å§‹ã•ã‚ŒãŸã“ã¨ã‚’è¨˜éŒ²ï¼ˆæ¬¡å›ãƒªãƒ­ãƒ¼ãƒ‰æ™‚ã«ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’é–‰ã˜ã‚‹ï¼‰
    if not st.session_state.processing_started:
        st.session_state.processing_started = True
    
    idx = st.session_state.current_idx
    
    if idx < len(uploaded_files):
        # ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ï¼ˆFile Uploadã¨Pathã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä¸¡å¯¾å¿œï¼‰
        file_item = uploaded_files[idx]
        if isinstance(file_item, Path):
            try:
                pil_img = Image.open(file_item)
                filename = file_item.name
            except Exception as e:
                st.error(f"âŒ Cannot open image: {str(e)}")
                st.stop()
        else:
            try:
                pil_img = Image.open(file_item)
                filename = file_item.name
            except Exception as e:
                st.error(f"âŒ Cannot open image: {str(e)}")
                st.stop()
        
        st.subheader(f"Step {idx+1}/{len(uploaded_files)}: Select Fovea for `{filename}`")
        
        orig_w, orig_h = pil_img.size
        
        # ã‚¯ãƒªãƒƒã‚¯ç¢ºå®šå‰ã‹ç¢ºå®šå¾Œã‹ã§è¡¨ç¤ºã‚’åˆ‡ã‚Šæ›¿ãˆ
        if idx not in st.session_state.fovea_clicked:
            # ã¾ã ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã„ãªã„å ´åˆ: ç”»åƒå…¨ä½“ã‚’è¡¨ç¤ºã—ã¦ã‚¯ãƒªãƒƒã‚¯ã‚’å—ã‘ä»˜ã‘ã‚‹
            st.info("ğŸ‘† Click the center of the fovea on the image")
            # ç¢ºèªç”»åƒã¨åŒã˜ã‚µã‚¤ã‚ºã§è¡¨ç¤ºï¼ˆä¸€ç¬ã§åˆ‡ã‚Šæ›¿ã‚ã‚‹ã‚ˆã†ã«ï¼‰
            value = streamlit_image_coordinates(pil_img, key=f"fovea_{idx}", width=orig_w)
            
            if value is not None:
                display_w = value.get('width', orig_w)
                display_h = value.get('height', orig_h)
                if not display_w:
                    display_w = orig_w
                if not display_h:
                    display_h = orig_h
                
                # Check for zero division
                if display_w <= 0 or display_h <= 0:
                    st.error("âŒ Invalid image display dimensions")
                    st.stop()
                
                x_click = value.get('x', 0)
                y_click = value.get('y', 0)
                fx = int(x_click * (orig_w / display_w))
                fy = int(y_click * (orig_h / display_h))
                
                # ã‚¯ãƒªãƒƒã‚¯ä½ç½®ã‚’ä¿å­˜ã—ã¦ç”»é¢ã‚’å†æç”»
                st.session_state.fovea_clicked[idx] = (fx, fy)
                st.rerun()
        
        else:
            # ã‚¯ãƒªãƒƒã‚¯æ¸ˆã¿: ç¢ºèªç”»åƒã¨ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
            fx, fy = st.session_state.fovea_clicked[idx]
            
            # ROIç¯„å›²ã‚’æç”»ã—ãŸç¢ºèªç”»åƒã‚’ä½œæˆ
            preview_img = np.array(pil_img.convert('RGB'))
            scale_px_per_mm_h = orig_w / scan_w
            
            # 3.0mm ROIç¯„å›²ã‚’æç”»
            roi_width_px = int(3.0 * scale_px_per_mm_h)
            roi_start_x = max(0, int(fx - roi_width_px / 2))
            roi_end_x = min(orig_w, roi_start_x + roi_width_px)
            
            # ROIç¯„å›²ã‚’é’ã„ç·šã§æç”»
            cv2.line(preview_img, (roi_start_x, 0), (roi_start_x, orig_h), (255, 0, 0), 3)
            cv2.line(preview_img, (roi_end_x, 0), (roi_end_x, orig_h), (255, 0, 0), 3)
            
            # ä¸­å¿ƒç‚¹ã‚’ç·‘ã®å††ã§æç”»
            cv2.circle(preview_img, (fx, fy), 10, (0, 255, 0), -1)
            
            st.success("âœ… Fovea position selected!")
            
            # ç”»åƒã¨ãƒœã‚¿ãƒ³ã‚’é‡ã­ã¦è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ã‚³ãƒ³ãƒ†ãƒŠ
            img_container = st.container()
            with img_container:
                # ç”»åƒã‚’è¡¨ç¤º
                st.image(preview_img, caption="Confirmation: Blue lines = 3.0mm ROI range, Green circle = Fovea center", width=orig_w)
            
            # Reselectãƒœã‚¿ãƒ³ã‚’ç”»åƒã®å³ä¸Šã«é‡ã­ã‚‹ï¼ˆãƒã‚¬ãƒ†ã‚£ãƒ–ãƒãƒ¼ã‚¸ãƒ³ã‚’ä½¿ç”¨ï¼‰
            st.markdown("""
            <style>
                .reselect-overlay {
                    margin-top: -50px;
                    margin-bottom: 10px;
                    display: flex;
                    justify-content: flex-end;
                    padding-right: 10px;
                }
            </style>
            """, unsafe_allow_html=True)
            
            st.markdown('<div class="reselect-overlay">', unsafe_allow_html=True)
            if st.button("ğŸ”„ Reselect", key=f"reselect_{idx}", type="secondary"):
                del st.session_state.fovea_clicked[idx]
                st.rerun()
            st.markdown('</div>', unsafe_allow_html=True)
            
            # Confirm & Analyze ã¨ Skip This Image ãƒœã‚¿ãƒ³ã‚’é…ç½®
            col1, col2 = st.columns(2)
            with col1:
                if st.button("âœ… Confirm & Analyze", type="primary", key=f"confirm_{idx}", use_container_width=True):
                    # --- Auto-initialization logic ---
                    if 'processor' not in st.session_state:
                        with st.spinner("ğŸ”„ Loading AI model for the first time..."):
                            st.session_state.processor = CVIProcessor()
                            st.session_state.processor.initialize_model()
                    
                    with st.spinner(f"ğŸ”¬ Analyzing {filename}..."):
                        res, v_cvi, v_dcvi = st.session_state.processor.process_image(
                            pil_img, filename, fx, fy, scan_w, depth_r
                        )
                        
                        if res is not None:
                            st.session_state.results.append(res)
                            if v_cvi is not None:
                                st.session_state.vis_files[f"CVI_{filename}"] = v_cvi
                            if v_dcvi is not None:
                                st.session_state.vis_files[f"DCVI_{filename}"] = v_dcvi
                            st.session_state.current_idx += 1
                            st.rerun()
                        else:
                            st.error(f"âŒ Failed to process image")
            
            with col2:
                if st.button("â­ï¸ Skip This Image", key=f"skip_{idx}", use_container_width=True):
                    st.warning(f"â­ï¸ Skipped: {filename}")
                    st.session_state.current_idx += 1
                    st.rerun()
    else:
        st.success("ğŸ‰ Analysis Complete!")
        df = pd.DataFrame(st.session_state.results)
        st.dataframe(df)
        
        # --- Folder Batchãƒ¢ãƒ¼ãƒ‰: ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã«ä¿å­˜ ---
        if mode == "Folder Batch" and output_folder:
            try:
                # å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ä½œæˆï¼ˆå…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼åã‚’å«ã‚€ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ï¼‰
                input_folder_name = Path(input_folder).name if input_folder else "output"
                now_str = datetime.now().strftime('%Y%m%d_%H%M%S')
                out_root = Path(output_folder) / f"{input_folder_name}_CVI_{now_str}"
                out_root.mkdir(parents=True, exist_ok=True)
                
                # CSVä¿å­˜
                df.to_csv(out_root / "cvi_results.csv", index=False)
                
                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ­ã‚°ä¿å­˜
                log_df = pd.DataFrame({
                    'Parameter': ['Macro Name', 'Developer', 'Date', 'Time', 
                                  'Original Folder', 'Analyzed by', 
                                  'Scan Width (H-mm)', 'Depth Range (V-mm)', 
                                  'Total Images', 'Success'],
                    'Value': [APP_NAME, DEVELOPER, 
                              datetime.now().strftime('%Y-%m-%d'), 
                              datetime.now().strftime('%H:%M:%S'),
                              input_folder_name, author,
                              scan_w, depth_r,
                              len(uploaded_files), len(st.session_state.results)]
                })
                log_df.to_csv(out_root / f"{input_folder_name}_Parameter.csv", index=False)
                
                # å¯è¦–åŒ–ç”»åƒä¿å­˜
                for fname, fdata in st.session_state.vis_files.items():
                    if fdata is not None:
                        with open(out_root / fname, 'wb') as f:
                            f.write(fdata)
                
                st.success(f"âœ… Results saved to: `{out_root}`")
                
                if st.button("ğŸ”„ Start New Batch"):
                    for key in ['current_idx', 'results', 'vis_files', 'fovea_clicked']:
                        if key in st.session_state: 
                            del st.session_state[key]
                    st.rerun()
                    
            except Exception as e:
                st.error(f"âŒ Error saving to output folder: {str(e)}")
        
        # --- File Uploadãƒ¢ãƒ¼ãƒ‰: Zipãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ---
        elif mode == "File Upload":
            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, "a", zipfile.ZIP_DEFLATED, False) as zip_file:
                # CSVè¿½åŠ 
                csv_data = df.to_csv(index=False).encode('utf-8')
                zip_file.writestr("cvi_results.csv", csv_data)
                
                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ­ã‚°è¿½åŠ 
                log_df = pd.DataFrame({
                    'Parameter': ['App', 'Author', 'Date', 'Time', 'Scan Width', 'Depth Range'],
                    'Value': [APP_NAME, author, datetime.now().strftime('%Y-%m-%d'), 
                             datetime.now().strftime('%H:%M:%S'), scan_w, depth_r]
                })
                zip_file.writestr("parameters.csv", log_df.to_csv(index=False).encode('utf-8'))
                
                # å¯è¦–åŒ–ç”»åƒè¿½åŠ 
                for fname, fdata in st.session_state.vis_files.items():
                    if fdata is not None:
                        zip_file.writestr(fname, fdata)
            
            col1, col2 = st.columns(2)
            with col1:
                st.download_button(
                    label="ğŸ“¥ Download All Results (Zip)",
                    data=zip_buffer.getvalue(),
                    file_name=f"CVI_Results_{datetime.now().strftime('%Y%m%d_%H%M')}.zip",
                    mime="application/zip",
                    type="primary"
                )
            
            with col2:
                if st.button("ğŸ”„ Reset Session"):
                    for key in ['current_idx', 'results', 'vis_files', 'fovea_clicked']:
                        if key in st.session_state: 
                            del st.session_state[key]
                    st.rerun()
else:
    if mode == "Folder Batch":
        st.warning("âš ï¸ Please specify input and output folder paths in the sidebar")
    else:
        st.warning("âš ï¸ Please upload B-scan images in the sidebar")